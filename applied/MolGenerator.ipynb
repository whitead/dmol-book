{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative RNN in Browser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This chapter builds on the model and information presented in {doc}`../dl/NLP`. We'll see how to develop, train, and deploy a model to a website. The goal is to develop a model that can propose new molecules. A \"molecule\" is a broad term, so we'll restrict ourselves to molecules like those that might be used for a small molecule drug. There is an existing database for this task called [ZINC](http://zinc15.docking.org/) (recursive acronym: *ZINC is not commercial*). The ZINC database contains 750 million molecules (as SMILES) that **can be purchased directly**. By training with ZINC, you are restricting your training distribution to molecules that can be synthesized.{cite}`sterling2015zinc`\n",
    "\n",
    "750 million molecules is often enough. Instead of generating new molecules with a model, you can just sample from ZINC and be assured that each molecule is purchasable. Sometimes that is not possible because we're more interested in building a representation (a vector for each molecule), rather than actually sampling like in self-supervised learning. My recommendation in projects is to strongly consider just using ZINC directly if possible. We'll continue on for our approach, because we may go on to use the RNN for \"downstream tasks\" like predicting solubility using the self-supervised trained RNN.\n",
    "\n",
    "You can see the final idea of what we're trying to accomplish in this chapter at [whitead.github.io/molecule-dream/](https://whitead.github.io/molecule-dream/). This model was generated using our final code at the bottom. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running This Notebook\n",
    "\n",
    "\n",
    "Click the &nbsp;<i aria-label=\"Launch interactive content\" class=\"fas fa-rocket\"></i>&nbsp; above to launch this page as an interactive Google Colab. See details below on installing packages, either on your own environment or on Google Colab\n",
    "\n",
    "````{tip} My title\n",
    ":class: dropdown\n",
    "To install packages, execute this code in a new cell\n",
    "\n",
    "```\n",
    "!pip install matplotlib numpy tensorflow pandas seaborn rdkit-pypi \"selfies<2\" tensorflowjs\n",
    "```\n",
    "\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach 1: Token Sampling\n",
    "\n",
    "At first, it may seem simple to generate new molecules. Any sequence of SELFIES is a valid molecule {cite}`krenn2020self`. Let's start by trying this approach -- making random sequences. Recall that a sequence is an array of tokens, like characters or words. In SELFIES, the tokens are very clear because they are enclosed by square brackets. For example,`[C][C]` is a SELFIES sequence with two tokens. \n",
    "\n",
    "We want to generate new molecules similar to ZINC remember, so we'll start by extracting all unique tokens from that database. To save everyone a little time, we'll work with a subset of ZINC that has about 250,000 molecules that comes from the SELFIES repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import selfies as sf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import rdkit, rdkit.Chem, rdkit.Chem.Draw\n",
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "from dataclasses import dataclass\n",
    "import seaborn as sns\n",
    "\n",
    "np.random.seed(0)\n",
    "IPythonConsole.ipython_useSVG = True\n",
    "sns.set_context(\"notebook\")\n",
    "sns.set_style(\n",
    "    \"dark\",\n",
    "    {\n",
    "        \"xtick.bottom\": True,\n",
    "        \"ytick.left\": True,\n",
    "        \"xtick.color\": \"#666666\",\n",
    "        \"ytick.color\": \"#666666\",\n",
    "        \"axes.edgecolor\": \"#666666\",\n",
    "        \"axes.linewidth\": 0.8,\n",
    "    },\n",
    ")\n",
    "color_cycle = [\"#1BBC9B\", \"#F06060\", \"#5C4B51\", \"#F3B562\", \"#6e5687\"]\n",
    "mpl.rcParams[\"axes.prop_cycle\"] = mpl.cycler(color=color_cycle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_url = \"https://github.com/aspuru-guzik-group/selfies/raw/16a489afa70882428bc194b2b24a2d33573f1651/examples/vae_example/datasets/dataJ_250k_rndm_zinc_drugs_clean.txt\"\n",
    "pd_data = pd.read_csv(data_url)\n",
    "print(\"Total data size\", len(pd_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have our starting dataset. To extract the SELFIES tokens, we need to convert the dataset (which is in SMILES) into SELFIES. This might take a while..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selfies_list = [sf.encoder(s) for s in pd_data.iloc[:, 0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's what one of the examples look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(selfies_list[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's extract now all the possible tokens and count them. I'll initialize my list with the '[nop]' token, which is the SELFIES null token we'll use later for padding. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selfies_symbol_counts = {\"[nop]\": 0}\n",
    "\n",
    "\n",
    "def parse(s):\n",
    "    for si in s.split(\"[\")[1:]:\n",
    "        token = \"[\" + si\n",
    "        if token in selfies_symbol_counts:\n",
    "            selfies_symbol_counts[token] += 1\n",
    "        else:\n",
    "            selfies_symbol_counts[token] = 0\n",
    "\n",
    "\n",
    "[parse(s) for s in selfies_list]\n",
    "\n",
    "# print out topic tokens\n",
    "sorted_token_counts = list(sorted(selfies_symbol_counts.items(), key=lambda i: -i[1]))\n",
    "for p in sorted_token_counts[:10]:\n",
    "    print(*p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll finish up parsing by creating a dictionary to go back from string to index and a list for our vocab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = list(selfies_symbol_counts.keys())\n",
    "vocab_stoi = {o: i for o, i in zip(vocab, range(len(vocab)))}\n",
    "\n",
    "\n",
    "def selfies2ints(s):\n",
    "    result = []\n",
    "    for si in s.split(\"[\")[1:]:\n",
    "        result.append(vocab_stoi[\"[\" + si])\n",
    "    return result\n",
    "\n",
    "\n",
    "def ints2selfies(v):\n",
    "    return \"\".join([vocab[i] for i in v])\n",
    "\n",
    "\n",
    "# test them out\n",
    "s = selfies_list[0]\n",
    "print(\"selfies:\", s)\n",
    "v = selfies2ints(s)\n",
    "print(\"selfies2ints:\", v)\n",
    "so = ints2selfies(v)\n",
    "print(\"ints2selfes:\", so)\n",
    "assert so == s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll try sampling directly from the tokens. I'm not very good at inferring if a SELFIES string is a reasonable molecule, so we'll render a few using rdkit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model1():\n",
    "    # pick random length\n",
    "    length = np.random.randint(1, 100)\n",
    "    seq = np.random.choice(len(vocab), size=length)\n",
    "    return seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_examples(model, count=10):\n",
    "    examples = [ints2selfies(model()) for _ in range(9)]\n",
    "    examples_smiles = [sf.decoder(s) for s in examples]\n",
    "    from rdkit.Chem import rdDepictor\n",
    "\n",
    "    examples_mols = [rdkit.Chem.MolFromSmiles(s) for s in examples_smiles]\n",
    "    return rdkit.Chem.Draw.MolsToGridImage(\n",
    "        examples_mols, molsPerRow=3, subImgSize=(250, 250)\n",
    "    )\n",
    "\n",
    "\n",
    "draw_examples(model1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, these molecules are a bit extreme -- we see bizarre valences and highly unusual combinations of elements. We can try to sample now according to the frequency of tokens we saw in the corpus (ZINC smiles)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get sorted token counts to be order\n",
    "# same as vocab\n",
    "token_counts = [\n",
    "    x[1] for x in sorted(sorted_token_counts, key=lambda i: vocab_stoi[i[0]])\n",
    "]\n",
    "token_counts = np.array(token_counts)\n",
    "\n",
    "\n",
    "def model2():\n",
    "    # pick random length\n",
    "    length = np.random.randint(1, 100)\n",
    "    seq = np.argmax(\n",
    "        np.random.multinomial(1, token_counts / np.sum(token_counts), size=length),\n",
    "        axis=-1,\n",
    "    )\n",
    "    return seq\n",
    "\n",
    "\n",
    "# now draw\n",
    "draw_examples(model2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are much better! Still, they are very exotic -- if they could even be synthesized they would probably explode if you sneezed on them. The advantage of SELFIES over SMILES is that none of these were invalid. Just a bit unreasonable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach 2: Token RNN\n",
    "\n",
    "Our next approach will be to use a recurrent neural network as we did in {doc}`../dl/NLP`. We will make one major change. The RNN will be trained to predict a whole sequence instead of one value (like solubility). This training process is called self-supervised. We create labels, from splitting up the training data, so it is not exactly unsupervised.\n",
    "\n",
    "The way we implement self-supervised training with an RNN is that we feed it a sequence up to position $i-1$ and then ask it to predict the sequence value at position $i$. Then at inference time, we feed its output at $i - 1$ as the input to $i$. There are a few tricks to make this efficient. The first is that if we split our data into all possible pairs of training labels (sequence up to $i - 1$) and labels (value at $i$), we'll have $N\\times L$ examples which in our case is about 100 million. To treat this, we'll consider the predicted label to be the whole sequence $\\vec{\\hat{y}}$  and that will include each individual prediction challenge. For example, predicting $\\hat{y}$ given $x_0, x_1, x_2$ will be the value of $\\vec{\\hat{y}}$ at index 3.\n",
    "\n",
    "You'll notice there is a bit of a length mismatch with this approach. What would $\\hat{y}_0$ correspond to? You might say it is the predicted label without any input features, but RNNs require an input to have an output. Instead, we'll prefix every sequence with the special `[nop]` token which means do nothing. Then $\\hat{0}$ will be the prediction given a `[nop]` token. We just need to remember at inference time we need to always begin with the `[nop]` token to match the training conditions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by building our training set using the splitting process. I'm going to define all my hyperparameters in one place as well, so I can easily view them. These hyperparameters are mostly first guesses built from previous experience with GRUs for sequence modeling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Config:\n",
    "    vocab_size: int\n",
    "    example_number: int\n",
    "    batch_size: int\n",
    "    buffer_size: int\n",
    "    embedding_dim: int\n",
    "    rnn_units: int\n",
    "\n",
    "\n",
    "config = Config(\n",
    "    vocab_size=len(vocab),\n",
    "    example_number=len(selfies_list),\n",
    "    batch_size=64,\n",
    "    buffer_size=10000,\n",
    "    embedding_dim=256,\n",
    "    rnn_units=128,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now get sequences\n",
    "encoded = [selfies2ints(s) for s in selfies_list]\n",
    "# Keras pads with 0s - [nop] in our vocab\n",
    "padded_seqs = tf.keras.preprocessing.sequence.pad_sequences(encoded, padding=\"post\")\n",
    "\n",
    "# Now build dataset\n",
    "seqs_data = tf.data.Dataset.from_tensor_slices((padded_seqs,))\n",
    "\n",
    "\n",
    "def split_input_target(sequence):\n",
    "    # remove last input (since no label exists)\n",
    "    # prefix with [nop]\n",
    "    input_text = tf.concat(([0], sequence[:-1]), 0)\n",
    "    target_text = sequence\n",
    "    return input_text, target_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = seqs_data.map(split_input_target)\n",
    "data = (\n",
    "    data.shuffle(config.buffer_size)\n",
    "    .batch(config.batch_size, drop_remainder=True)\n",
    "    .prefetch(tf.data.experimental.AUTOTUNE)\n",
    ")\n",
    "# grab examples\n",
    "for d in data:\n",
    "    example = d[0]\n",
    "    example_y = d[1]\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Construction\n",
    "\n",
    "Our model will be the same as {doc}`../dl/NLP`: an embedding, one RNN (GRU variant), and one dense layer. The dense layer could be omitted if an even simpler model was desired. We do not add a softmax to the dense layer because we'll be working with logits instead of probability in training and inference. One change is that we specify the `return_sequences` since we're training across sequences. The other flags to {obj}`tf.keras.layers.GRU` are to set-up for deploying the model to javascript, which we'll see below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.keras.Input(shape=(None,))\n",
    "ex = tf.keras.layers.Embedding(\n",
    "    input_dim=config.vocab_size, output_dim=config.embedding_dim, mask_zero=True\n",
    ")(x)\n",
    "# reset_after - TFJS requires this as false\n",
    "h = tf.keras.layers.GRU(\n",
    "    config.rnn_units, return_sequences=True, reset_after=False, stateful=False\n",
    ")(ex)\n",
    "yhat = tf.keras.layers.Dense(config.vocab_size)(h)\n",
    "train_model = tf.keras.Model(inputs=x, outputs=yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll call it once to make sure it works and to enable Keras to set all the unknown dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = train_model(example)\n",
    "train_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "Now we will train the model. We use a special loss function {obj}`tf.losses.SparseCategoricalCrossentropy` that works on a sequence of logits for computing cross-entropy in the multi-class setting (multi-class because we have multiple possible tokens). I will train for only 2 epochs to reduce the runtime of this notebook, but I've found ~4 is a reasonable balance of time and loss. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "train_model.compile(tf.optimizers.Adam(1e-2), loss=loss)\n",
    "result = train_model.fit(data, epochs=2, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference\n",
    "\n",
    "In the inference setting, we need to feed the output from each step back into the model to generate the next token. RNNs are defined by the input and their **state vector** (or state vectors for LSTM). To ensure our model is not forgetting about the tokens it has seen so far, we could keep the state and last output token to use as input to the model. However, an easier approach is to make the underlying model **stateful**. That means its state will be stored as a kind of internal weight and we do not need to bother with passing around the state vector. \n",
    "\n",
    "We'll construct a second model that is stateful and make its weights equal to the one we trained. Another change is that we do not need the model to output the whole sequence since we're generating one token at a time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.keras.Input(shape=(None,), batch_size=1)\n",
    "ex = tf.keras.layers.Embedding(\n",
    "    input_dim=config.vocab_size, output_dim=config.embedding_dim, mask_zero=True\n",
    ")(x)\n",
    "h = tf.keras.layers.GRU(\n",
    "    config.rnn_units, return_sequences=False, reset_after=False, stateful=True\n",
    ")(ex)\n",
    "yhat = tf.keras.layers.Dense(config.vocab_size)(h)\n",
    "inference_model = tf.keras.Model(inputs=x, outputs=yhat)\n",
    "\n",
    "# now copy over weights\n",
    "inference_model.set_weights(train_model.get_weights())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To try the model, remember we start with the `[nop]` token which is zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 4))\n",
    "x = np.array([0])\n",
    "v = inference_model.predict(x)\n",
    "plt.bar(x=np.arange(config.vocab_size), height=np.squeeze(v))\n",
    "plt.xlabel(\"Token index\")\n",
    "plt.ylabel(\"Log odds\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the logit probability for each token. We need to sample from this to get our prediction for the first token. We'll sample it with an adjustable parameter called **temperature**. Temperature controls how close we are to sampling the maximum. $T = 0$ means we sampling the max only, $T = 1$ means we sample according to the logits, and $T = \\infty$ means we sample randomly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_token(x, T=1):\n",
    "    return tf.random.categorical(x / T, 1)\n",
    "\n",
    "\n",
    "t = sample_token(v)\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to continue we feed back into the stateful model. Let's wrap this into a function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_model(T=1):\n",
    "    length = np.random.randint(1, 100)\n",
    "    seq = []\n",
    "    x = tf.zeros((1,))\n",
    "    # reset stateful model\n",
    "    inference_model.reset_states()\n",
    "    for _ in range(length):\n",
    "        v = inference_model.predict(x)\n",
    "        x = sample_token(v, T)\n",
    "        seq.append(int(np.squeeze(x.numpy())))\n",
    "    return seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll draw the output for $T = 1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_examples(sample_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are better still! Now we can try adjusting the temperature to see more unusual or more common molecules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$T = 0.5$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_examples(lambda: sample_model(T=0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$T = 100$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_examples(lambda: sample_model(T=100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that the $T = 0.5$ case seems to works the best of the three."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, to get the model into javascript as shown at [Molecule Dream](https://whitead.github.io/molecule-dream/) we can export using tensorflowjs. It is relatively simple, but you may notice when you load the model into javascript that console errors may indicate you need to adjust flags in model construction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflowjs as tfjs\n",
    "\n",
    "tfjs.converters.save_keras_model(inference_model, \"tfjs_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I also like to save the config in case I need to know things like the vocab or dimension of the vectors. JSON files can be easily loaded into javascript objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from dataclasses import asdict\n",
    "\n",
    "model_info = asdict(config)\n",
    "model_info[\"stoi\"] = vocab_stoi\n",
    "model_info[\"vocab\"] = vocab\n",
    "\n",
    "\n",
    "with open(\"tfjs_model/config.json\", \"w\") as f:\n",
    "    json.dump(model_info, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start by seeing how we load the model code. This section requires some knowledge of javascript. This javascript code loads the model and config JSON file. Then it creates two functions - `model(t)` and `resetStates()` which are the two ways we use our model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```js\n",
    "import * as tf from '@tensorflow/tfjs';\n",
    "import config from 'tfjs_model/config.json;\n",
    "\n",
    "const rnn_mod = {}\n",
    "\n",
    "const loader = tf.loadLayersModel('/tfjs_model/model.json');\n",
    "loader.then((model) => {\n",
    "    rnn_mod.model = (t) => {\n",
    "        return model.predict(t);\n",
    "    }\n",
    "    rnn_mod.resetStates = () => {\n",
    "        model.resetStates();\n",
    "    }\n",
    "});\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we need a few helper functions that we used for inference. These are sampling and for converting from integers to the SELFIES tokens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```js\n",
    "rnn_mod.sample = (x, seed, T = 0.1, k = 1) => {\n",
    "    return tf.multinomial(\n",
    "        tf.mul(tf.scalar(2.0), x), k, seed\n",
    "    );\n",
    "}\n",
    "\n",
    "rnn_mod.selfie2vec = (s) => {\n",
    "    const vec = tf.tensor(s.split('[').slice(1).map((e, i) => {\n",
    "        if (e)\n",
    "            parseInt(config.stoi['[' + e]);\n",
    "    }));\n",
    "    return vec;\n",
    "}\n",
    "\n",
    "rnn_mod.initVec = () => {\n",
    "    return tf.tensor([0]);\n",
    "}\n",
    "\n",
    "rnn_mod.vec2selfie = (v) => {\n",
    "    const out = v.array().then((x) => {\n",
    "        if (Array.isArray(x)) {\n",
    "            return x.map((e, i) => {\n",
    "                return config.vocab[parseInt(e)];\n",
    "            });\n",
    "        } else {\n",
    "            return [config.vocab[parseInt(x)]];\n",
    "        }\n",
    "    });\n",
    "\n",
    "    return out;\n",
    "}\n",
    "\n",
    "export default rnn_mod;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code gives us a javascript module that can then be used for sampling from our trained model. See the [Molecular Dream repo](https://github.com/whitead/molecule-dream/) for the complete code. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cited References\n",
    "\n",
    "```{bibliography}\n",
    ":style: unsrtalpha\n",
    ":filter: docname in docnames\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
