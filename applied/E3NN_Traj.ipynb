{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TDHJMVqgha5a"
   },
   "source": [
    "# Equivariant Neural Network for Predicting Trajectories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Foy9ZA_f6MZu"
   },
   "source": [
    "```{admonition} Authors:\n",
    "[Sam Cox](https://github.com/SamCox822)\n",
    "```\n",
    "\n",
    "In this example, we will train an equivariant neural network to predict the next frame in the trajectory alignment example (10.6). As stated in 10.3.8, for time-dependent trajectories, we do not need to concern ourselves with permutation equivariance because it is implied that the order of the points does not change. Thus, we can treat this example as a simple set of coordinates in 3D space, meaning that any deep learning model that we train on this data should have rotation, mirror/parity, and translation equivariance. In other words, our model should be O(3) equivariant. E3NN {cite}`e3nn` is a library built to create equivariant neural networks for the this group, so it's a great choice for this problem.\n",
    "\n",
    "We will use the trajectory data from that example to train our network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0CzF_Lh_mfBb"
   },
   "source": [
    "## Retrieving Data from Trajectory Alignment Example\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "maitjJ0J8FkZ"
   },
   "source": [
    "First, let's use the same imports and visualization used in Chapter 10 to download our data and view the first frame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ix1niSUbhrKl"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import urllib\n",
    "import urllib.request\n",
    "import numpy as np\n",
    "import jax\n",
    "import jax.numpy as jnp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 636
    },
    "id": "OYD-Y4Ihhuw2",
    "outputId": "35ebb4a8-2721-41e9-d5b7-65d6d36ae715"
   },
   "outputs": [],
   "source": [
    "urllib.request.urlretrieve(\n",
    "    \"https://github.com/whitead/dmol-book/raw/master/data/paths.npz\", \"paths.npz\"\n",
    ")\n",
    "paths = np.load(\"paths.npz\")[\"arr\"]\n",
    "# plot the first point\n",
    "plt.title(\"First Frame\")\n",
    "plt.plot(paths[0, :, 0], paths[0, :, 1], \"o-\")\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yYGRiXdsqukN"
   },
   "source": [
    "## Additional Installations and Imports\n",
    "## Running This Notebook\n",
    "\n",
    "\n",
    "Click the &nbsp;<i aria-label=\"Launch interactive content\" class=\"fas fa-rocket\"></i>&nbsp; above to launch this page as an interactive Google Colab. See details below on installing packages.\n",
    "\n",
    "````{tip} My title\n",
    ":class: dropdown\n",
    "To install packages, execute this code in a new cell. \n",
    "\n",
    "```\n",
    "!pip install torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric -f https://data.pyg.org/whl/torch-1.11.0+cpu.html\n",
    "\n",
    "!pip install e3nn\n",
    "\n",
    "!pip install dmol-book\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HCMPyneStz1J"
   },
   "outputs": [],
   "source": [
    "# additional imports\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Data, Dataset, DataLoader\n",
    "import torch\n",
    "import e3nn\n",
    "import math\n",
    "from e3nn.nn.models.gate_points_2101 import Network\n",
    "from e3nn import o3\n",
    "import dmol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LM7b2GuBtREx"
   },
   "source": [
    "## Baseline Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bWClrr7YtUKB"
   },
   "source": [
    "Before we build our E3NN network, it's always a good idea to build a baseline model for comparision. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6yBv8SVXnO-g"
   },
   "outputs": [],
   "source": [
    "def mse(y, yhat):\n",
    "    return np.mean((yhat - y) ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tS5-BvF3jvQb"
   },
   "source": [
    "First, let's discuss what the input and output should be for this model. The input should be the coordinates of the 12 points: one frame. What should the output be? We want to train a neural network to predict the next trajectory for each point, the next frame, so our output should actually be the same type as our input.\n",
    "\n",
    "Thus,\n",
    "\n",
    "**Inputs:**\n",
    "* 12 sets of coordinates\n",
    "\n",
    "**Outputs:**\n",
    "* 12 sets of coordinates\n",
    "\n",
    "Note: since we are trying to build an O(3)-equivariant neural network, which should be equivariant to transformations in 3D space, we need to make these coordinates 3D. This is easy, we will just put zero for the z-coordiantes. We'll do this now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZqUhDfvZjrSY"
   },
   "outputs": [],
   "source": [
    "traj_3d = np.array([])\n",
    "for i in range(2048):\n",
    "    for j in range(12):\n",
    "        TBA = paths[i][j]\n",
    "        TBA = np.append(\n",
    "            TBA,\n",
    "            np.array(\n",
    "                [\n",
    "                    0.00,\n",
    "                ]\n",
    "            ),\n",
    "        )\n",
    "        traj_3d = np.append(traj_3d, TBA)\n",
    "\n",
    "traj_3d = traj_3d.reshape(2048, 12, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AsEANrCelJcm"
   },
   "source": [
    "Interestingly, for this example, we want our prediction from one frame to match the following frame. So our features and labels will be nearly identical, offset by one.\n",
    "\n",
    "For the features, we want to include everything except for the final frame, which has no \"next frame\" in our data. We can extrapolate with our model to predict this \"next frame\" as a final step if we want. \n",
    "\n",
    "For our lables, we want to include everything except for the first step, which is not the \"next frame\" of anything in our data. \n",
    "\n",
    "We can also go ahead and split our data into training and testing sets. \n",
    "\n",
    "Let's do approximately an 80:20 split here.\n",
    "We want to make sure not to shuffle our data, as we are predicting time-series data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SYkPIqO5lMUS",
    "outputId": "7686b4ad-89a5-438d-8f8d-8bd6eb4e329a"
   },
   "outputs": [],
   "source": [
    "features = traj_3d[:-1]\n",
    "labels = traj_3d[1:]\n",
    "\n",
    "# split data 80:20\n",
    "training_set = features[:1637]\n",
    "training_labels = labels[:1637]\n",
    "valid_set = features[1637:]\n",
    "valid_labels = labels[1637:]\n",
    "\n",
    "# convert to jnp arrays\n",
    "training_setbl = jnp.asarray(training_set)\n",
    "training_labelsbl = jnp.asarray(training_labels)\n",
    "\n",
    "valid_setbl = jnp.asarray(valid_set)\n",
    "valid_labelsbl = jnp.asarray(valid_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3-L0ZAiylQke"
   },
   "source": [
    "Let's check to make sure our data matches up. Frame 2 in the features set should be the same as Frame 1 in the labels set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "viwGHptQlQEP",
    "outputId": "e00088db-fa18-4117-94cd-68ad57c8d27c"
   },
   "outputs": [],
   "source": [
    "print(\"features, frame 2: \\n\", features[1])\n",
    "print(\"labels, frame 1: \\n\", labels[0])\n",
    "if mse(features[1], labels[0]) == 0:\n",
    "    print(\"success! they match!\")\n",
    "else:\n",
    "    print(mse(features[1], labels[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l1zkI8WylWKp"
   },
   "source": [
    "Great, they match! Now we are ready to build our baseline model!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "knROsKpMPq9G"
   },
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def baseline_model(inputs, w, b):\n",
    "    yhat = inputs @ w + b\n",
    "    return yhat\n",
    "\n",
    "\n",
    "def baseline_loss(inputs, y, w, b):\n",
    "    return mse(y, baseline_model(inputs, w, b))\n",
    "\n",
    "\n",
    "bl_loss_grad = jax.grad(baseline_loss, (2, 3))\n",
    "\n",
    "w = np.zeros((3, 3))\n",
    "w = jnp.asarray(w)\n",
    "b = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 280
    },
    "id": "gwVTp4xqP6ox",
    "outputId": "f0035b27-4fba-410c-9a8a-991d52a5705d"
   },
   "outputs": [],
   "source": [
    "epochs = 16\n",
    "eta = 1e-6\n",
    "\n",
    "baseline_val_loss = [0.0 for _ in range(epochs)]\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for d in range(1637):\n",
    "        inputs = training_setbl[d]\n",
    "        y = training_labelsbl[d]\n",
    "        grad_bl = bl_loss_grad(inputs, y, w, b)\n",
    "        # update w & b\n",
    "        w -= eta * grad_bl[0]\n",
    "        b -= eta * grad_bl[1]\n",
    "\n",
    "    for i in range(410):\n",
    "        inputs_v = valid_setbl[i]\n",
    "        y_v = valid_labelsbl[i]\n",
    "        baseline_val_loss[epoch] += baseline_loss(inputs_v, y_v, w, b)\n",
    "    baseline_val_loss[epoch] = jnp.sqrt(baseline_val_loss[epoch] / 410)\n",
    "    eta *= 0.9\n",
    "\n",
    "\n",
    "plt.plot(baseline_val_loss)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Val Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hrJIJzQJuhcz",
    "outputId": "90e6d968-81ee-4e9e-ff79-cf59497fd0dc"
   },
   "outputs": [],
   "source": [
    "print(\"Final loss value: \", baseline_val_loss[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gcsLpaa-9_og"
   },
   "source": [
    "Now let's view a parity plot to see if we're learning the right trend here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 676
    },
    "id": "dTkdDKk_95oM",
    "outputId": "7008c653-fc65-48c1-d23f-05edfe6d8205"
   },
   "outputs": [],
   "source": [
    "ys = jnp.array([])\n",
    "yhats = jnp.array([])\n",
    "\n",
    "for i in range(205):\n",
    "    inputs_v = valid_setbl[i]\n",
    "    ys = jnp.append(ys, valid_labelsbl[i])\n",
    "    yhat = baseline_model(inputs_v, w, b)\n",
    "    yhats = jnp.append(yhats, yhat)\n",
    "\n",
    "plt.plot(ys, ys, \"-\")\n",
    "plt.plot(ys, yhats, \".\")\n",
    "plt.xlabel(\"Trajectory\")\n",
    "plt.ylabel(\"Predicted Trajectory\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D_XufdCT-SrP"
   },
   "source": [
    "This is difficult to read, since our xyz coordinates are very different in magnitude. Instead, let's look at three plots, one for each coordinate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "tR4cM9EA-dSY",
    "outputId": "40daf9b0-853e-48fe-ae32-22b9e4e883ab"
   },
   "outputs": [],
   "source": [
    "ys_x = jnp.array([])\n",
    "ys_y = jnp.array([])\n",
    "ys_z = jnp.array([])\n",
    "yh_x = jnp.array([])\n",
    "yh_y = jnp.array([])\n",
    "yh_z = jnp.array([])\n",
    "\n",
    "for i in range(205):\n",
    "    inputs_v = valid_setbl[i]\n",
    "    y = valid_labelsbl[i]\n",
    "    yhat = baseline_model(inputs_v, w, b)\n",
    "\n",
    "    ys_x = jnp.append(ys_x, y[i][0])\n",
    "    ys_y = jnp.append(ys_y, y[i][1])\n",
    "    ys_z = jnp.append(ys_z, y[i][2])\n",
    "\n",
    "    yh_x = jnp.append(yh_x, yhat[i][0])\n",
    "    yh_y = jnp.append(yh_y, yhat[i][1])\n",
    "    yh_z = jnp.append(yh_z, yhat[i][2])\n",
    "\n",
    "plt.plot(ys_x, ys_x, \"-\")\n",
    "plt.plot(ys_x, yh_x, \".\")\n",
    "plt.xlabel(\"X-Coordinate of Trajectory\")\n",
    "plt.ylabel(\"X-Coordinate of Predicted Trajectory\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(ys_y, ys_y, \"-\")\n",
    "plt.plot(ys_y, yh_y, \".\")\n",
    "plt.xlabel(\"Y-Coordinate of Trajectory\")\n",
    "plt.ylabel(\"Y-Coordinate of Predicted Trajectory\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(ys_z, ys_z, \"-\")\n",
    "plt.plot(ys_z, yh_z, \".\")\n",
    "plt.xlabel(\"Z-Coordinate of Trajectory\")\n",
    "plt.ylabel(\"Z-Coordinate of Predicted Trajectory\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NouYVoRS-y_v"
   },
   "source": [
    "It looks like we are starting to get the right trend for some of the coordinates, but more training is definitely needed. However, as stated, we want any model that uses this data to be equivariant in 3D space. Let's check the equivariances now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qRezFDFVCqEZ",
    "outputId": "c82a097b-5ecc-481e-b6c9-06092f5784c1"
   },
   "outputs": [],
   "source": [
    "# checking for rotation equivariance\n",
    "import scipy.spatial.transform as trans\n",
    "\n",
    "# rotate around x coordinate by 80 degrees\n",
    "rot = trans.Rotation.from_euler(\"x\", 80, degrees=True)\n",
    "\n",
    "input_point = jnp.asarray(np.random.normal(size=(12, 3)))\n",
    "w_test1 = jnp.asarray(np.random.normal(size=(3, 3)))\n",
    "\n",
    "input_rot = rot.apply(input_point)\n",
    "output_1 = baseline_model(input_rot, w_test1, b)\n",
    "output_prerot = baseline_model(input_point, w_test1, b)\n",
    "output_rot = []\n",
    "for xyz in output_prerot:\n",
    "    coord = rot.apply(xyz)\n",
    "    output_rot.append(coord)\n",
    "output_rot = jnp.array(output_rot)\n",
    "\n",
    "print(\"rotated first: \\n\", output_1)\n",
    "print(\"rotated last: \\n\", output_rot)\n",
    "print(\"\\033[1m\" + \"difference: \" + \"\\033[0m\", mse(output_1, output_rot))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4wL-4mgCFQMU"
   },
   "source": [
    "So it doesn't look like our baseline model is rotation-equivariant. This is important, because we if we give our model coordinates that are rotated, we expect the output should be rotated by the same degree. Likewise, we need translation equivariance. Let's check that now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N_Fg_KHyFm2q",
    "outputId": "5bd1f7ed-3c41-4aa7-936a-b43643798e3b"
   },
   "outputs": [],
   "source": [
    "# checking for translation equivariance\n",
    "random_trans = jnp.asarray(np.random.normal(size=(12, 3)))\n",
    "\n",
    "input_trans = input_point + random_trans\n",
    "output_2 = baseline_model(input_trans, w_test1, b)\n",
    "output_trans = random_trans + baseline_model(input_point, w_test1, b)\n",
    "\n",
    "print(\"translated first: \", output_2)\n",
    "print(\"translated last: \", output_trans)\n",
    "print(\"\\033[1m\" + \"difference: \" + \"\\033[0m\", mse(output_2, output_trans))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sYCwyP87GtrB"
   },
   "source": [
    "As expected, our model isn't translation equviariant either. I won't prove that we don't have parity/inversion equivariance, but you should expect that this baseline model will not have any spatial equivariance. \n",
    "\n",
    "We can solve this problem many ways. One way is to augment our data in order to teach our model equivariance. This requires more training and data storage, so let's look at a more compact approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T7WKHiYthx86"
   },
   "source": [
    "## E3NN Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jQIgZvoEjs3Q"
   },
   "source": [
    "E3NN is a library for creating equivariant neural networks, specifically in E(3). E3NN is built for spatial equvariance in 3-D space. Specifically, this library gives us equivariance with respect to the E(3) group of rotations, inversions, and translations. As discussed before, the time-dependent trajectory's points do not change order, so we do not need to worry about permutation equivariance/invariance in this case; we only need E(3)-equivariance. E3NN is a great tool for this problem because we have 3-dimensional points in space, and if we transform them in space, we want the output to transform the same way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pZfb8eErlXg7"
   },
   "source": [
    "E3NN works through the use of irreducible representations (irreps). In general, representations tell you how to interact with the data with repect to the group. When creating a model, we give the model the irreps so that it knows how to handle the data we will give it during trianing. It's not necessary to understand what the irreps are; instead, just know that they are the smallest representations, which are similar to, and transform the same way as, the spherical harmonics. Any (reducible) representation can be decomposed into irreducible representations. If you want to know more, you can check out more on the E3NN documentation website [@e3nn]. Let's take a look at how the irreps are used in this context. \n",
    "\n",
    "For this group, we need to find the L and d for each piece of data, where $d = 2L + 1$ (d = dimension). Look at the table below. \n",
    "\n",
    "| **parity** | **L** | **d** | **name**      |\n",
    "|------------|-------|-------|---------------|\n",
    "| even       | 0     | 1     | scalar        |\n",
    "| odd        | 0     | 1     | pseudo scalar |\n",
    "| even       | 1     | 3     | pseudo vector |\n",
    "| odd        | 1     | 3     | vector        |\n",
    "| even       | 2     | 5     |       -       |\n",
    "| odd        | 2     | 5     |       -       |\n",
    "|            |       |       |               |\n",
    "\n",
    "The general notation is **MxLp**, where M is the number, L is the L from the table above, and p corresponds to the parity (e: even, o: odd). \n",
    "\n",
    "For example, if you wanted to portray \"12 scalars, 4 vectors\" in this format, you would write **\"12x0e + 4x1o\"**. Take a minute to make sure you understand how to use this notation, as it's essential for E3NN. E3NN deals with equivariance by receiving the irreps as a model parameter. This allows the E3NN framework to know how each input feature/output transforms under symmetry, so that it can treat each piece appropriately. As a side note, the output of an E3NN model must always be of equal or higher symmetry than your input.\n",
    "\n",
    "Because E3NN is built to handle 3D spatial data, we do not need to tell the model that we are going to give it 3D coordinates; it's implicit and **required**. The irreps_in, instead, correspond to the input node features. In this example, we don't have input features, but as an example, you can imagine we could want our model to predict the next set of coordinates, given the intitial coordinates and the velocity. In that case, our irreps_in would be the velocity. If we gave our velocity as vectors, we would have **\"12x1o\"\"** as our input features. If we just gave our model the magnitude of the velocity, we would represent our input features as **\"12x0e\"**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Msab78GJlbrF"
   },
   "source": [
    "Since we don't have input features, we'll put \"None\" for that parameter, and we want our output to be the same shape as the input: 12 vectors. However, since we are trying to predict 12 vectors out for 12 vectors in, we only need to tell the model to predict 1 vector per input **\"1x1o\"**. Take a minute to make sure you understand why this is the case. In this case, you can think of the model recognizing 12 input vectors and predicting a vector for each. Again, E3NN expects coordinate inputs, so we don't specify this for the input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PRq67aBWrXh0"
   },
   "source": [
    "## E3NN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dx55lICsrgTH"
   },
   "source": [
    "E3NN has several models within their library, which can be found [on the E3NN github page here](https://github.com/e3nn/e3nn/tree/main/e3nn/nn/models). For this example, we will use one of these models. \n",
    "\n",
    "To use the E3NN model, we need to turn our data into a torch_geometric dataset. We'll do that now. Then we can split our data into training and testing sets.\n",
    "\n",
    "Also, instead of directly computing the next frame, we'll change it here to predict the distance to the next frame. This is a small change, but having data centered nearer zero is better for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4a2CF_bbv4_N",
    "outputId": "0dfddad9-b138-4885-c9f4-8d665cfb9c01"
   },
   "outputs": [],
   "source": [
    "feat = torch.from_numpy(features)  # convert to pytorch tensors\n",
    "ys = torch.from_numpy(labels)  # convert to pytorch tensors\n",
    "traj_data = []\n",
    "distances = ys - feat  # compute distances to next frame\n",
    "\n",
    "\n",
    "# make torch_geometric dataset\n",
    "# we want this to be an interable list\n",
    "# x = None because we have no input features\n",
    "for frame, label in zip(feat, distances):\n",
    "    traj_data += [\n",
    "        torch_geometric.data.Data(\n",
    "            x=None, pos=frame.to(torch.float32), y=label.to(torch.float32)\n",
    "        )\n",
    "    ]\n",
    "\n",
    "train_split = 1637\n",
    "train_loader = torch_geometric.data.DataLoader(\n",
    "    traj_data[:train_split], batch_size=1, shuffle=False\n",
    ")\n",
    "\n",
    "test_split = 1842\n",
    "test_loader = torch_geometric.data.DataLoader(\n",
    "    traj_data[train_split:test_split], batch_size=1, shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZjVxk_cwVBX-"
   },
   "source": [
    "Great! Now we're ready to define our model. Since this is a pre-built model in E3NN, so we just need to import it and define the model parameters. Note that the state of this model will save automatically, so you will need to reinitialize the model every time you want to start training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FcptjZtGB4Oc"
   },
   "outputs": [],
   "source": [
    "from e3nn.nn.models.gate_points_2101 import Network\n",
    "from e3nn import o3\n",
    "\n",
    "model_kwargs = {\n",
    "    \"irreps_in\": None,  # no input features\n",
    "    \"irreps_hidden\": o3.Irreps(\"5x0e + 5x0o + 5x1e + 5x1o\"),  # hyperparameter\n",
    "    \"irreps_out\": \"1x1o\",  # 12 vectors out, but only 1 vector out per input\n",
    "    \"irreps_node_attr\": None,\n",
    "    \"irreps_edge_attr\": o3.Irreps.spherical_harmonics(3),\n",
    "    \"layers\": 3,  # hyperparameter\n",
    "    \"max_radius\": 3.5,\n",
    "    \"number_of_basis\": 10,\n",
    "    \"radial_layers\": 1,\n",
    "    \"radial_neurons\": 128,\n",
    "    \"num_neighbors\": 11,  # average number of neighbors w/in max_radius\n",
    "    \"num_nodes\": 12,  # not important unless reduce_output is True\n",
    "    \"reduce_output\": False,  # setting this to true would give us one scalar as an output.\n",
    "}\n",
    "\n",
    "model = Network(**model_kwargs)  # initializing model with parameters above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T7UOAxB7xcFE"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# this will print an outline of the model architecture!\n",
    "eta = 1e-6\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=eta)\n",
    "optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sAJAqOY-s3TZ",
    "outputId": "43f04e3c-7041-46b5-9e78-c1617a94cd1f"
   },
   "outputs": [],
   "source": [
    "epochs = 16\n",
    "\n",
    "val_loss = [0.0 for _ in range(epochs)]\n",
    "tr_loss = [0.0 for _ in range(epochs)]\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for step, data in enumerate(train_loader):\n",
    "        yhat = model(data)\n",
    "        loss_1 = torch.mean((yhat - data.y) ** 2)\n",
    "        tr_loss[epoch] += (loss_1).detach()\n",
    "        loss_1.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    tr_loss[epoch] = tr_loss[epoch] / 1637\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for step, data in enumerate(test_loader):\n",
    "            yhat = model(data)\n",
    "            loss2 = torch.mean((yhat - data.y) ** 2)\n",
    "            val_loss[epoch] += (loss2).detach()\n",
    "    val_loss[epoch] = val_loss[epoch] / 205"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 674
    },
    "id": "262rPIy2QNi-",
    "outputId": "00e0c3c3-bcdc-4d5a-d8fe-4594012c4025"
   },
   "outputs": [],
   "source": [
    "v_loss = torch.tensor(val_loss)\n",
    "t_loss = torch.tensor(tr_loss)\n",
    "\n",
    "\n",
    "plt.plot(t_loss, label=\"Testing Loss\")\n",
    "plt.plot(v_loss, label=\"Validation Loss\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TjRx285tsQ6N",
    "outputId": "ff182e13-6b76-4cf7-9f1e-d1efbc793a3e"
   },
   "outputs": [],
   "source": [
    "print(\"final loss value: \", val_loss[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jqu6o27P0KFA"
   },
   "source": [
    "Let's look at the last (extrapolated) frame from the E3NN model, compared to the baseline model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "1TFEteyZxQhS",
    "outputId": "111ccde3-7e3c-4079-ca08-1203aa9364d3"
   },
   "outputs": [],
   "source": [
    "last_frame_bl = y_v\n",
    "last_frame_e3nn = yhat\n",
    "\n",
    "plt.title(\"Last Frame Baseline\")\n",
    "plt.plot(last_frame_bl[:, 0], last_frame_bl[:, 1], \"o-\")\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.show()\n",
    "\n",
    "plt.title(\"Last Frame e3nn\")\n",
    "plt.plot(last_frame_e3nn[:, 0], last_frame_e3nn[:, 1], \"o-\")\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "isEXdrcezs15"
   },
   "source": [
    "Interestingly, it looks like the baseline model predicted a frame that looks more like what we'd expect, even though the loss is much lower in the E3NN model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CsgSyfwyZ1xc"
   },
   "source": [
    "Remember that we trained our model to predict the displacement. We can convert back by just adding our dispacement vectors back to their previous frame. We won't do it here, but we could do it to extrapolate our E3NN model to predict the next frame *not* included in the dataset. For now, we have a reasonably well trained model, and we could finish by testing our model for equivariance using the method described [here](https://docs.e3nn.org/en/stable/guide/equivar_testing.html)."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of Predicting_Trajectories_with_E3NN.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
