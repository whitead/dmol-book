
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />
<meta content="Deep Learning for Molecules &amp; Materials Book" lang="en" name="description" xml:lang="en" />
<meta content="en_US" property="og:locale" />
<meta content="summary" name="twitter:card" />
<meta content="Deep Learning for Molecules &amp; Materials Book" name="twitter:description" />
<meta content="dmol.pub üìñ" name="twitter:title" />
<meta content="https://dmol.pub/_static/logo.png" name="twitter:image" />
<meta content="&#64;andrewwhite01" name="twitter:site" />

    <title>1. Tensors and Shapes &#8212; deep learning for molecules &amp; materials</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css?v=9c3e77be" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.8ecb98da25f57f5357bf6f572d296f466b2cfe2517ffebfabe82451661e28f02.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="../_static/custom.css?v=cb1cce99" />
    <link rel="stylesheet" type="text/css" href="../_static/a11y.css?v=ffeaf963" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js?v=1ae7504c"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'math/tensors-and-shapes';</script>
    <script src="../_static/custom.js?v=3f5092eb"></script>
    <link rel="canonical" href="https://dmol.pub/math/tensors-and-shapes.html" />
    <link rel="icon" href="../_static/favicon.png"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="2. Introduction to Machine Learning" href="../ml/introduction.html" />
    <link rel="prev" title="Overview" href="../index.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/logo.png" class="logo__image only-light" alt="deep learning for molecules & materials - Home"/>
    <script>document.write(`<img src="../_static/logo.png" class="logo__image only-dark" alt="deep learning for molecules & materials - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../index.html">
                    Overview
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">A. Math Review</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 current active"><a class="current reference internal" href="#">1. Tensors and Shapes</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">B. Machine Learning</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../ml/introduction.html">2. Introduction to Machine Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ml/regression.html">3. Regression &amp; Model Assessment</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ml/classification.html">4. Classification</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ml/kernel.html">5. Kernel Learning</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">C. Deep Learning</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../dl/introduction.html">6. Deep Learning Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../dl/layers.html">7. Standard Layers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../dl/gnn.html">8. Graph Neural Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../dl/data.html">9. Input Data &amp; Equivariances</a></li>
<li class="toctree-l1"><a class="reference internal" href="../dl/Equivariant.html">10. Equivariant Neural Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../dl/xai.html">11. Explaining Predictions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../dl/attention.html">12. Attention Layers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../dl/NLP.html">13. Deep Learning on Sequences</a></li>
<li class="toctree-l1"><a class="reference internal" href="../dl/VAE.html">14. Variational Autoencoder</a></li>
<li class="toctree-l1"><a class="reference internal" href="../dl/flows.html">15. Normalizing Flows</a></li>
<li class="toctree-l1"><a class="reference internal" href="../dl/molnets.html">16. Modern Molecular NNs</a></li>

</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">D. Applications</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../applied/QM9.html">17. Predicting DFT Energies with GNNs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../applied/MolGenerator.html">18. Generative RNN in Browser</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">E. Contributed Chapters</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../applied/e3nn_traj.html">19. Equivariant Neural Network for Predicting Trajectories</a></li>
<li class="toctree-l1"><a class="reference internal" href="../dl/pretraining.html">20. Pretraining</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">F. Appendix</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../style.html">21. Style Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../changelog.html">22. Changelog</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://colab.research.google.com/github/whitead/dmol-book/blob/master/math/tensors-and-shapes.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch on Colab"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img alt="Colab logo" src="../_static/images/logo_colab.png">
  </span>
<span class="btn__text-container">Colab</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/whitead/dmol-book" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/whitead/dmol-book/issues/new?title=Issue%20on%20page%20%2Fmath/tensors-and-shapes.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/math/tensors-and-shapes.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Tensors and Shapes</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#einstein-notation">1.1. Einstein Notation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#tensor-operations">1.2. Tensor Operations</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#reduction-operations">1.2.1. Reduction Operations</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#element-operations">1.2.2. Element Operations</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#broadcasting">1.3. Broadcasting</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#suggested-reading-for-broadcasting">1.3.1. Suggested Reading for Broadcasting</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#modifying-rank">1.4. Modifying Rank</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#reshaping">1.4.1. Reshaping</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#rank-slicing">1.4.2. Rank Slicing</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#view-vs-copy">1.5. View vs Copy</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#chapter-summary">1.6. Chapter Summary</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#exercises">1.7. Exercises</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">1.7.1. Einstein notation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#reductions">1.7.2. Reductions</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#broadcasting-and-shapes">1.7.3. Broadcasting and Shapes</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cited-references">1.8. Cited References</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="tensors-and-shapes">
<h1><span class="section-number">1. </span>Tensors and Shapes<a class="headerlink" href="#tensors-and-shapes" title="Link to this heading">#</a></h1>
<p>This textbook will draw upon linear algebra, vector calculus, and probability theory. Each chapter states the expected background in an <code class="docutils literal notranslate"><span class="pre">Audience</span> <span class="pre">&amp;</span> <span class="pre">Objectives</span></code> admonition (see example below). This math review fills in details missing from those typical classes: working with tensors. If you would like a chemistry-focused background on those topics, you can read the online book <a class="reference external" href="https://unitcirclepress.com/"><em>Mathematical Methods for Molecule Sciences</em> by John Straub</a><span id="id1">[<a class="reference internal" href="#id191" title="J Straub. Mathematical methods for molecular science. 2020.">Str20</a>]</span>.</p>
<p>Tensors are the generalization of vectors (rank 1) and matrices (rank 2) to arbitrary <strong>rank</strong>. Rank can be defined as the number of indices required to get individual elements of a tensor. A matrix requires two indices (row, column), and is thus a rank 2 tensor. We may say in normal conversation that a matrix is a ‚Äútwo-dimensional object‚Äù because it has rows and columns, but this is ambiguous because the row could be 6 dimensions and the columns could be 1 dimension. Always use the word rank to distinguish vectors, matrices, and higher-order tensors. The components that make up rank are called <strong>axes</strong> (plural of <strong>axis</strong>). The <strong>dimension</strong> is how many elements are in a particular axis. The <strong>shape</strong> of a tensor combines all of these. A shape is a tuple (ordered list of numbers) whose length is the rank and elements are the dimension of each axis.</p>
<div class="admonition-audience-objectives admonition">
<p class="admonition-title">Audience &amp; Objectives</p>
<p>You should have a background in linear algebra and basic Python programming to read this chapter. After reading, you should be able to</p>
<ul class="simple">
<li><p>Define a tensor and specify one in Python</p></li>
<li><p>Modify tensor rank, shape, and axes</p></li>
<li><p>Use Einstein notation to define equations/expressions of tensors</p></li>
<li><p>Understand and use broadcasting rules to work with tensors</p></li>
</ul>
</div>
<aside class="margin sidebar">
<p class="sidebar-title">Rank</p>
<p><a class="reference external" href="https://mathworld.wolfram.com/TensorRank.html">Tensor rank</a> and <a class="reference external" href="https://mathworld.wolfram.com/MatrixRank.html">matrix rank</a> are two different concepts. Matrix rank
is the number of linearly independent columns and has nothing to do with tensor rank. Some authors may use <em>order</em> to refer to tensor rank to distinguish the two terms.</p>
</aside>
<p>Let‚Äôs practice our new vocabulary. A Euclidean vector <span class="math notranslate nohighlight">\((x, y, z)\)</span> is a rank 1 tensor whose 0th axis is dimension 3. Its shape is <span class="math notranslate nohighlight">\((3)\)</span>. Beautiful. A 5 row, 4 column matrix is now called a rank 2 tensor whose axes are dimension 5 and 4. Its shape is <span class="math notranslate nohighlight">\((5, 4)\)</span>. The scalar (real number) 3.2 is a rank 0 tensor whose shape is <span class="math notranslate nohighlight">\(()\)</span>.</p>
<p>TensorFlow has a <a class="reference external" href="https://www.tensorflow.org/guide/tensor">nice visual guide to tensors</a>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Array and tensor are synonyms. Array is the preferred word
in numpy and often used when describing tensors in Python. Tensor is the mathematic
equivalent.</p>
</div>
<section id="einstein-notation">
<h2><span class="section-number">1.1. </span>Einstein Notation<a class="headerlink" href="#einstein-notation" title="Link to this heading">#</a></h2>
<p>Einstein notation is the way tensor operations can be written out. We‚Äôll be using a simplified version, based on the <code class="docutils literal notranslate"><span class="pre">einsum</span></code> function available in many numerical libraries (<a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.einsum.html#numpy.einsum" title="(in NumPy v2.4)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">np.einsum</span></code></a>, <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/einsum" title="(in TensorFlow v2.8)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">tf.einsum</span></code></a>, <a class="reference external" href="https://docs.jax.dev/en/latest/_autosummary/jax.numpy.einsum.html#jax.numpy.einsum" title="(in JAX)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">jnp.einsum</span></code></a>). It‚Äôs relatively simple. Each tensor is written as a lower case variable with explicit indices, like <span class="math notranslate nohighlight">\(a_{ijk}\)</span> for a rank 3 tensor. The reason the variable name is written in lower case is because if you fill in the indices <span class="math notranslate nohighlight">\(a_{023}\)</span>, you get a scalar.  A variable without an index, <span class="math notranslate nohighlight">\(b\)</span>, is a scalar. There is one rule for this notation: if an index doesn‚Äôt appear on both sides of the equation, it is summed over on the one side in which it appears. Einstein notation requires both sides of the equation to be written-out, so that its clear what the input/output shapes of the operation are.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>The concept of Tensors from physics involves a more complex picture of connecting algebraic sets of objects, typically vectors in a space. Here we just treat tensors as a synonym for multidimensional array. Be aware that looking-up tensor on wikipedia will bring you to the physics picture.</p>
</div>
<p>Here are some examples of writing tensor operations in Einstein notation.</p>
<p><strong>Total Sum</strong></p>
<p>Sum all elements of a rank 4 tensor. In Einstein notation this is:</p>
<div class="amsmath math notranslate nohighlight" id="equation-8217af37-550e-4655-a5da-ff2ea88626d6">
<span class="eqno">(1.1)<a class="headerlink" href="#equation-8217af37-550e-4655-a5da-ff2ea88626d6" title="Permalink to this equation">#</a></span>\[\begin{equation}
  a_{ijkl} = b
\end{equation}\]</div>
<p>in normal mathematic notation, this would be</p>
<div class="amsmath math notranslate nohighlight" id="equation-096f59ca-bed3-47c2-bc96-4ff0733f1d91">
<span class="eqno">(1.2)<a class="headerlink" href="#equation-096f59ca-bed3-47c2-bc96-4ff0733f1d91" title="Permalink to this equation">#</a></span>\[\begin{equation}
\sum_i \sum_j \sum_k \sum_l a_{ijkl} = b
\end{equation}\]</div>
<aside class="margin sidebar">
<p class="sidebar-title"></p>
<p>There even is a framework-independent Einstein notation library that
enables you to use this notation across multiple frameworks for neural network layers.
It is called <a class="reference external" href="https://einops.rocks/">einops</a></p>
</aside>
<p><strong>Sum Specific Axis</strong></p>
<p>Sum over last axis</p>
<div class="amsmath math notranslate nohighlight" id="equation-b428bbda-ca44-45f7-b998-46129dfac141">
<span class="eqno">(1.3)<a class="headerlink" href="#equation-b428bbda-ca44-45f7-b998-46129dfac141" title="Permalink to this equation">#</a></span>\[\begin{equation}
  a_{ijkl} = b_{ijk}
\end{equation}\]</div>
<p>In normal notation:</p>
<div class="amsmath math notranslate nohighlight" id="equation-7e19aef1-788b-4bb8-a31c-a35880bb3b26">
<span class="eqno">(1.4)<a class="headerlink" href="#equation-7e19aef1-788b-4bb8-a31c-a35880bb3b26" title="Permalink to this equation">#</a></span>\[\begin{equation}
 \sum_l a_{ijkl} = b_{ijk}
\end{equation}\]</div>
<p><strong>Dot Product</strong></p>
<p>In Einstein notation:</p>
<div class="amsmath math notranslate nohighlight" id="equation-cbe7acae-2d79-4dca-b55d-74f07fd1c974">
<span class="eqno">(1.5)<a class="headerlink" href="#equation-cbe7acae-2d79-4dca-b55d-74f07fd1c974" title="Permalink to this equation">#</a></span>\[\begin{equation}
  a_{i} b_{i} = c
\end{equation}\]</div>
<p>In normal notation:</p>
<div class="amsmath math notranslate nohighlight" id="equation-3944f987-9475-4413-be5e-d6e511db0396">
<span class="eqno">(1.6)<a class="headerlink" href="#equation-3944f987-9475-4413-be5e-d6e511db0396" title="Permalink to this equation">#</a></span>\[\begin{equation}
  \sum_i a_{i} b_{i} = c
\end{equation}\]</div>
<p>Notice that <span class="math notranslate nohighlight">\(a_i\)</span> and <span class="math notranslate nohighlight">\(b_i\)</span> must have the same dimension in their 0th axis in order for the sum in the dot product to be valid. This makes sense, since to compute a dot product the vectors must be the same dimension. In general, if two tensors share the same index (<span class="math notranslate nohighlight">\(b_{ij}\)</span>, <span class="math notranslate nohighlight">\(a_{ik}\)</span>), then that axis must be the same dimension.</p>
<p>Can you write the following out in Einstein notation?</p>
<p><strong>Matrix Multiplication</strong></p>
<p>The matrix product of 2 tensors, where each tensor is rank 2.</p>
<div class="dropdown admonition">
<p class="admonition-title">Answer</p>
<div class="amsmath math notranslate nohighlight" id="equation-4e5e615a-eca3-4f53-abae-8953ca70820f">
<span class="eqno">(1.7)<a class="headerlink" href="#equation-4e5e615a-eca3-4f53-abae-8953ca70820f" title="Permalink to this equation">#</a></span>\[\begin{equation}
    a_{ij} b_{jk} = c_{ik}
\end{equation}\]</div>
</div>
<p><strong>Matrix Vector Product</strong></p>
<p>Apply matrix <span class="math notranslate nohighlight">\(a\)</span> to column vector <span class="math notranslate nohighlight">\(b\)</span> by multiplication. <span class="math notranslate nohighlight">\(\mathbf{A}\vec{b}\)</span> in linear algebra notation.</p>
<div class="dropdown admonition">
<p class="admonition-title">Answer</p>
<div class="amsmath math notranslate nohighlight" id="equation-726adf5e-a466-4393-830e-3e03f0a6aa84">
<span class="eqno">(1.8)<a class="headerlink" href="#equation-726adf5e-a466-4393-830e-3e03f0a6aa84" title="Permalink to this equation">#</a></span>\[\begin{equation}
    a_{ij} b_{j} = c_{i}
\end{equation}\]</div>
</div>
<p><strong>Matrix Transpose</strong></p>
<p>Swap the values in a matrix to make it a transpose.</p>
<div class="dropdown admonition">
<p class="admonition-title">Answer</p>
<div class="amsmath math notranslate nohighlight" id="equation-9d4e9a28-4106-4b3c-b1d1-983f693e8395">
<span class="eqno">(1.9)<a class="headerlink" href="#equation-9d4e9a28-4106-4b3c-b1d1-983f693e8395" title="Permalink to this equation">#</a></span>\[\begin{equation}
    a_{ij} = t_{ji}
\end{equation}\]</div>
</div>
</section>
<section id="tensor-operations">
<h2><span class="section-number">1.2. </span>Tensor Operations<a class="headerlink" href="#tensor-operations" title="Link to this heading">#</a></h2>
<aside class="margin sidebar">
<p class="sidebar-title">Why Tensors?</p>
<p>Tensors are the main building block
of modern deep learning. Nearly all
variables in equations are actually tensors.
Being able to understand how shape affects them
is the key to understanding how algorithms work.</p>
</aside>
<p>Although you can specify operations in Einstein notation, it is typically not expressive enough. How would you write this operation: sum the last axis of a tensor? Without knowing the rank, you do not know how many indices you should indicate in the expression. Maybe like this?</p>
<div class="amsmath math notranslate nohighlight" id="equation-c18ff1b0-9870-4300-a4ea-640b71391dc1">
<span class="eqno">(1.10)<a class="headerlink" href="#equation-c18ff1b0-9870-4300-a4ea-640b71391dc1" title="Permalink to this equation">#</a></span>\[\begin{equation}
a_{i_0, i_1, \ldots i_N} = a_{i_0, i_1, \ldots i_{N - 1}}
\end{equation}\]</div>
<p>Well, that‚Äôs good but what if your operation has two arguments: which axis to sum and the tensor. That would also be clumsy to write. Einstein notation is useful and we‚Äôll see it more, but we need to think about <strong>tensor operations</strong> as analogies to functions. Tensor operations take in 1 or more tensors and output 1 or more tensors and the output shape depends on the input shape.</p>
<p>One of the difficult things about tensors is understanding how shape is treated in equations. For example, consider this equation:</p>
<div class="amsmath math notranslate nohighlight" id="equation-792b0491-391c-4ebe-bd1e-9448e770f85d">
<span class="eqno">(1.11)<a class="headerlink" href="#equation-792b0491-391c-4ebe-bd1e-9448e770f85d" title="Permalink to this equation">#</a></span>\[\begin{equation}
    g = \exp\left(a - b\right)^2
\end{equation}\]</div>
<p>Seems like a reasonable enough equation. But what if <span class="math notranslate nohighlight">\(a\)</span> is rank 3 and <span class="math notranslate nohighlight">\(b\)</span> is rank 1? Is <span class="math notranslate nohighlight">\(g\)</span> rank 1 or 3 then? Actually, this is taken from a real example where <span class="math notranslate nohighlight">\(g\)</span> was rank 4. You subtract each element of <span class="math notranslate nohighlight">\(b\)</span> from each element of <span class="math notranslate nohighlight">\(a\)</span>. You could write this in Einstein notation:</p>
<div class="amsmath math notranslate nohighlight" id="equation-4f91c7a2-d336-42e7-b39e-1ffa33afed7a">
<span class="eqno">(1.12)<a class="headerlink" href="#equation-4f91c7a2-d336-42e7-b39e-1ffa33afed7a" title="Permalink to this equation">#</a></span>\[\begin{equation}
    g_{ijkl} = \exp\left(a_{ijk} - b_l\right)^2
\end{equation}\]</div>
<p>except this function should work on arbitrary ranked <span class="math notranslate nohighlight">\(a\)</span> and always output <span class="math notranslate nohighlight">\(g\)</span> being the rank of <span class="math notranslate nohighlight">\(a + 1\)</span>. Typically, the best way to express this is explicitly stating how rank and shape are treated.</p>
<section id="reduction-operations">
<h3><span class="section-number">1.2.1. </span>Reduction Operations<a class="headerlink" href="#reduction-operations" title="Link to this heading">#</a></h3>
<p>Reduction operations reduce the rank of an input tensor. <a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.sum.html#numpy.sum" title="(in NumPy v2.4)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">np.sum(a,</span> <span class="pre">axis=0)</span></code></a> is an example. The axis argument means that we‚Äôre summing over the 0th axis so that it will be removed. If <code class="docutils literal notranslate"><span class="pre">a</span></code> is a rank 1 vector, this would leave us with a scalar. If <code class="docutils literal notranslate"><span class="pre">a</span></code> is a matrix, this would remove the rows so that only columns are left over. That means we would be left with <em>column sums</em>. You can also specify a tuple of axes to be removed, which will be done in that order <code class="docutils literal notranslate"><span class="pre">np.sum(a,</span> <span class="pre">axis=(0,1)</span> <span class="pre">)</span></code>.</p>
<p>In addition to <a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.sum.html#numpy.sum" title="(in NumPy v2.4)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">np.sum</span></code></a>, there are <a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.minimum.html#numpy.minimum" title="(in NumPy v2.4)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">np.minimum</span></code></a>, <a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.maximum.html#numpy.maximum" title="(in NumPy v2.4)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">np.maximum</span></code></a>, <a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.any.html#numpy.any" title="(in NumPy v2.4)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">np.any</span></code></a> (logical or), and more. Let‚Äôs see some examples</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>

<span class="n">a_shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">a_len</span> <span class="o">=</span> <span class="mi">4</span> <span class="o">*</span> <span class="mi">3</span> <span class="o">*</span> <span class="mi">2</span>

<span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">a_len</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">a_shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">a</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(4, 3, 2)
[[[ 0  1]
  [ 2  3]
  [ 4  5]]

 [[ 6  7]
  [ 8  9]
  [10 11]]

 [[12 13]
  [14 15]
  [16 17]]

 [[18 19]
  [20 21]
  [22 23]]]
</pre></div>
</div>
</div>
</div>
<p>Try to guess the shape of the output tensors using <code class="docutils literal notranslate"><span class="pre">a</span></code> in the below code based on what you‚Äôve learned.</p>
<div class="cell tag_hide-output docutils container">
<div class="cell_input above-output-prompt docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">b</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>
</pre></div>
</div>
</div>
<details class="admonition hide below-input">
<summary aria-label="Toggle hidden content">
<p class="collapsed admonition-title">Show code cell output</p>
<p class="expanded admonition-title">Hide code cell output</p>
</summary>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(3, 2)
[[36 40]
 [44 48]
 [52 56]]
</pre></div>
</div>
</div>
</details>
</div>
<div class="cell tag_hide-output docutils container">
<div class="cell_input above-output-prompt docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">c</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">a</span> <span class="o">&gt;</span> <span class="mi">4</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">c</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">c</span><span class="p">)</span>
</pre></div>
</div>
</div>
<details class="admonition hide below-input">
<summary aria-label="Toggle hidden content">
<p class="collapsed admonition-title">Show code cell output</p>
<p class="expanded admonition-title">Hide code cell output</p>
</summary>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(4, 2)
[[False  True]
 [ True  True]
 [ True  True]
 [ True  True]]
</pre></div>
</div>
</div>
</details>
</div>
<div class="cell tag_hide-output docutils container">
<div class="cell_input above-output-prompt docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">d</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">d</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">d</span><span class="p">)</span>
</pre></div>
</div>
</div>
<details class="admonition hide below-input">
<summary aria-label="Toggle hidden content">
<p class="collapsed admonition-title">Show code cell output</p>
<p class="expanded admonition-title">Hide code cell output</p>
</summary>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(4,)
[       0   332640  8910720 72681840]
</pre></div>
</div>
</div>
</details>
</div>
</section>
<section id="element-operations">
<h3><span class="section-number">1.2.2. </span>Element Operations<a class="headerlink" href="#element-operations" title="Link to this heading">#</a></h3>
<p>Default operations in Python, like <code class="docutils literal notranslate"><span class="pre">+</span></code> <code class="docutils literal notranslate"><span class="pre">-</span></code> <code class="docutils literal notranslate"><span class="pre">*</span></code> <code class="docutils literal notranslate"><span class="pre">/</span></code> <code class="docutils literal notranslate"><span class="pre">^</span></code> , are also tensor operations. They preserve shape so that the output shape is the same as the inputs‚Äô. The input tensors must have the same shape or be able to become the same shape through broadcasting, which is defined in the next section.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">a</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(4, 3, 2)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
<span class="n">b</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(4, 3, 2)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">c</span> <span class="o">=</span> <span class="n">a</span> <span class="o">*</span> <span class="n">b</span>
<span class="n">c</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(4, 3, 2)
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="broadcasting">
<h2><span class="section-number">1.3. </span>Broadcasting<a class="headerlink" href="#broadcasting" title="Link to this heading">#</a></h2>
<p>One of the difficulties with the elementary operations is that they require the input tensors to have the same shape. For example, you cannot multiply a scalar (rank 0) and a vector (rank 1). Of course, if you‚Äôre familiar with <code class="docutils literal notranslate"><span class="pre">numpy</span></code> this is common. It is done with <strong>broadcasting</strong> comes in. Broadcasting increases the rank of one of the input tensors to be compatible with another. Broadcasting works at the last axis and works its way forward. Let‚Äôs see an example</p>
<aside class="margin sidebar">
<p class="sidebar-title">Broadcasting order</p>
<p>Broadcasting starts at the last axis and
goes forward because getting an element
at the last axis gives a scalar (rank 0)
no matter what rank. This makes it possible to
copy to fill up axis to align shapes.</p>
</aside>
<div class="amsmath math notranslate nohighlight" id="equation-a12ef18f-bd48-4ed7-8fc8-4eb5da87a729">
<span class="eqno">(1.13)<a class="headerlink" href="#equation-a12ef18f-bd48-4ed7-8fc8-4eb5da87a729" title="Permalink to this equation">#</a></span>\[\begin{equation}
    A + B
\end{equation}\]</div>
<p><strong>Input A</strong></p>
<p>Rank 2, shape is (2, 3)</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">A</span><span class="p">:</span>
 <span class="mi">4</span>  <span class="mi">3</span>  <span class="mi">2</span> 
<span class="o">-</span><span class="mi">1</span>  <span class="mi">2</span>  <span class="mi">4</span>
</pre></div>
</div>
<p><strong>Input B</strong></p>
<p>Rank 1, shape is (3), a vector:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">B</span><span class="p">:</span> <span class="mi">3</span>  <span class="mi">0</span>  <span class="mi">1</span>
</pre></div>
</div>
<p>Now let‚Äôs see how the broadcasting works. Broadcasting starts by lining up the shapes from the end of the tensors</p>
<p><strong>Step 1: align on last axis</strong></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">tensor</span>        <span class="n">shape</span>
<span class="n">A</span><span class="p">:</span>             <span class="mi">2</span>  <span class="mi">3</span>
<span class="n">B</span><span class="p">:</span>                <span class="mi">3</span>
<span class="n">broadcasted</span> <span class="n">B</span><span class="p">:</span> <span class="o">.</span>  <span class="o">.</span>
</pre></div>
</div>
<p><strong>Step 2: process last axis</strong></p>
<p>Now broadcasting looks at the last axis (axis 1) and if one tensor has axis dimension 1, its value is copied to match the others. In our case, they agree.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">tensor</span>        <span class="n">shape</span>
<span class="n">A</span><span class="p">:</span>             <span class="mi">2</span>  <span class="mi">3</span>
<span class="n">B</span><span class="p">:</span>                <span class="mi">3</span>
<span class="n">broadcasted</span> <span class="n">B</span><span class="p">:</span> <span class="o">.</span>  <span class="mi">3</span>
</pre></div>
</div>
<p><strong>Step 3: process next axis</strong></p>
<p>Now we examine the next axis, axis 0. B has no axis there, because its rank is too low. Broadcasting will insert a new axis by (i) inserting a new axis with dimension 1 and (ii) copying the value at this new axis until its dimension matches.</p>
<p><strong>Step 3i:</strong></p>
<p>Add new axis of dimension 1. This is like making <span class="math notranslate nohighlight">\(B\)</span> have 1 row and 3 columns:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">B</span><span class="p">:</span>
 <span class="mi">3</span>  <span class="mi">0</span>  <span class="mi">1</span>
</pre></div>
</div>
<p><strong>Step 3ii:</strong></p>
<p>Now we copy the values of this axis until its dimension matches <span class="math notranslate nohighlight">\(A\)</span>‚Äôs axis 0 dimension. We‚Äôre basically copying <span class="math notranslate nohighlight">\(b_{0j}\)</span> to <span class="math notranslate nohighlight">\(b_{1j}\)</span>.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">B</span><span class="p">:</span>
 <span class="mi">3</span>  <span class="mi">0</span>  <span class="mi">1</span>
 <span class="mi">3</span>  <span class="mi">0</span>  <span class="mi">1</span>
</pre></div>
</div>
<p><strong>Final</strong></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">tensor</span>        <span class="n">shape</span>
<span class="n">A</span><span class="p">:</span>             <span class="mi">2</span>  <span class="mi">3</span>
<span class="n">B</span><span class="p">:</span>                <span class="mi">3</span>
<span class="n">broadcasted</span> <span class="n">B</span><span class="p">:</span> <span class="mi">2</span>  <span class="mi">3</span>
</pre></div>
</div>
<p>Now, we compute the result by addition elementwise.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">A</span> <span class="o">+</span> <span class="n">B</span>
  <span class="mi">4</span> <span class="o">+</span> <span class="mi">3</span>  <span class="mi">3</span> <span class="o">+</span> <span class="mi">0</span>  <span class="mi">2</span> <span class="o">+</span> <span class="mi">1</span>  <span class="o">=</span>   <span class="mi">7</span>  <span class="mi">3</span>  <span class="mi">3</span>
 <span class="o">-</span><span class="mi">1</span> <span class="o">+</span> <span class="mi">3</span>  <span class="mi">2</span> <span class="o">+</span> <span class="mi">0</span>  <span class="mi">4</span> <span class="o">+</span> <span class="mi">1</span>      <span class="mi">2</span>  <span class="mi">2</span>  <span class="mi">5</span>
</pre></div>
</div>
<hr class="docutils" />
<p>Let‚Äôs see some more examples, but only looking at the input/output shape</p>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head text-left"><p>A Shape</p></th>
<th class="head text-center"><p>B Shape</p></th>
<th class="head text-right"><p>Output Shape</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-left"><p>(4,2)</p></td>
<td class="text-center"><p>(4,1)</p></td>
<td class="text-right"><p>(4,2)</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>(4,2)</p></td>
<td class="text-center"><p>(2,)</p></td>
<td class="text-right"><p>(4,2)</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>(16,1,3)</p></td>
<td class="text-center"><p>(4,3)</p></td>
<td class="text-right"><p>(16,4,3)</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>(16,3,3)</p></td>
<td class="text-center"><p>(4,1)</p></td>
<td class="text-right"><p><code class="docutils literal notranslate"><span class="pre">Error</span></code></p></td>
</tr>
</tbody>
</table>
</div>
<p>Try some for yourself!</p>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head text-left"><p>A Shape</p></th>
<th class="head text-center"><p>B Shape</p></th>
<th class="head text-right"><p>Output Shape</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-left"><p>(7,4,3)</p></td>
<td class="text-center"><p>(1,)</p></td>
<td class="text-right"><p>?</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>(16, 16, 3)</p></td>
<td class="text-center"><p>(3,)</p></td>
<td class="text-right"><p>?</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>(2,4,5)</p></td>
<td class="text-center"><p>(5,4,1)</p></td>
<td class="text-right"><p>?</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>(1,4)</p></td>
<td class="text-center"><p>(16,)</p></td>
<td class="text-right"><p>?</p></td>
</tr>
</tbody>
</table>
</div>
<div class="dropdown admonition">
<p class="admonition-title">Answer</p>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head text-left"><p>A Shape</p></th>
<th class="head text-center"><p>B Shape</p></th>
<th class="head text-right"><p>Output Shape</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-left"><p>(7,4,3)</p></td>
<td class="text-center"><p>(1,)</p></td>
<td class="text-right"><p>(7,4,3)</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>(16, 16, 3)</p></td>
<td class="text-center"><p>(3,)</p></td>
<td class="text-right"><p>(16,16,3)</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>(2,4,5)</p></td>
<td class="text-center"><p>(5,4,1)</p></td>
<td class="text-right"><p><code class="docutils literal notranslate"><span class="pre">Error</span></code></p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>(1,4)</p></td>
<td class="text-center"><p>(16,)</p></td>
<td class="text-right"><p><code class="docutils literal notranslate"><span class="pre">Error</span></code></p></td>
</tr>
</tbody>
</table>
</div>
</div>
<section id="suggested-reading-for-broadcasting">
<h3><span class="section-number">1.3.1. </span>Suggested Reading for Broadcasting<a class="headerlink" href="#suggested-reading-for-broadcasting" title="Link to this heading">#</a></h3>
<p>You can read more about broadcastnig in the <a class="reference external" href="https://numpy.org/doc/stable/user/basics.broadcasting.html">numpy tutorial</a> or the <a class="reference external" href="https://jakevdp.github.io/PythonDataScienceHandbook/02.05-computation-on-arrays-broadcasting.html">Python Data Science Handbook</a>.</p>
</section>
</section>
<section id="modifying-rank">
<h2><span class="section-number">1.4. </span>Modifying Rank<a class="headerlink" href="#modifying-rank" title="Link to this heading">#</a></h2>
<aside class="margin sidebar">
<p class="sidebar-title">newaxis</p>
<p><code class="docutils literal notranslate"><span class="pre">newaxis</span></code> slices like <code class="docutils literal notranslate"><span class="pre">a[np.newaxis]</span></code> are possible
in tensorflow, jax, and numpy. In PyTorch there is <code class="docutils literal notranslate"><span class="pre">unsqueeze</span></code>.
You can also use <code class="docutils literal notranslate"><span class="pre">reshape</span></code> and ignore newaxis</p>
</aside>
<p>The last example we saw brings up an interesting questions: what if we want to add a (1,4) and (16,) to end up with a (16,4) tensor? We could insert a new axis at the end of <span class="math notranslate nohighlight">\(B\)</span> to make its shape (16, 1). This can be done using the <a class="reference external" href="https://numpy.org/doc/stable/reference/constants.html#numpy.newaxis" title="(in NumPy v2.4)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">np.newaxis</span></code></a> syntax:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span>
    <span class="mi">16</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">a</span> <span class="o">+</span> <span class="n">b</span><span class="p">[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span>
<span class="n">result</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(16, 4)
</pre></div>
</div>
</div>
</div>
<p>Just as newaxis can increase rank, we can decrease rank. One way is to just slice, like <code class="docutils literal notranslate"><span class="pre">a[0]</span></code>. A more general way is to <a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.squeeze.html#numpy.squeeze" title="(in NumPy v2.4)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">np.squeeze</span></code></a> which removes any axes that are dimension 1 without needing to know the specific axes that are dimension 1.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;before squeeze:&quot;</span><span class="p">,</span> <span class="n">a</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;after squeeze:&quot;</span><span class="p">,</span> <span class="n">a</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>before squeeze: (1, 32, 4, 1)
after squeeze: (32, 4)
</pre></div>
</div>
</div>
</div>
<p>It turns out that <code class="docutils literal notranslate"><span class="pre">np.newaxis</span></code> and <code class="docutils literal notranslate"><span class="pre">tf.newaxis</span></code> are actually defined as <code class="docutils literal notranslate"><span class="pre">None</span></code>. Some programmers will exploit this to save some keystrokes and use <code class="docutils literal notranslate"><span class="pre">None</span></code> instead:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span>
    <span class="mi">16</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">a</span> <span class="o">+</span> <span class="n">b</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">]</span>
<span class="n">result</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(16, 4)
</pre></div>
</div>
</div>
</div>
<p>I recommend against this because it can be a bit confusing and it‚Äôs really not saving that many keystrokes.</p>
<section id="reshaping">
<h3><span class="section-number">1.4.1. </span>Reshaping<a class="headerlink" href="#reshaping" title="Link to this heading">#</a></h3>
<p>The most general way of changing rank and shape is through <a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.reshape.html#numpy.reshape" title="(in NumPy v2.4)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">np.reshape</span></code></a>. This allows you to reshape a tensor, as long as the number of elements remains the same. You could make a (4, 2) into an (8,). You could make a (4, 3) into a (1, 4, 3, 1). Thus it can accomplish the two tasks done by <a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.squeeze.html#numpy.squeeze" title="(in NumPy v2.4)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">np.squeeze</span></code></a> and <a class="reference external" href="https://numpy.org/doc/stable/reference/constants.html#numpy.newaxis" title="(in NumPy v2.4)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">np.newaxis</span></code></a>.</p>
<p>There is one special syntax element to shaping:  A <code class="docutils literal notranslate"><span class="pre">-1</span></code> dimension. <code class="docutils literal notranslate"><span class="pre">-1</span></code> can appear once in a reshape command and means to have the computer figure out what goes there. We know the number of elements doesn‚Äôt change in a reshape, so the computer can infer what goes in the dimension marked as <code class="docutils literal notranslate"><span class="pre">-1</span></code>. Let‚Äôs see some examples.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">32</span><span class="p">)</span>
<span class="n">new_a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="n">new_a</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(4, 8)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">new_a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>
<span class="n">new_a</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(4, 8)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">new_a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>
<span class="n">new_a</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(1, 2, 2, 8)
</pre></div>
</div>
</div>
</div>
</section>
<section id="rank-slicing">
<h3><span class="section-number">1.4.2. </span>Rank Slicing<a class="headerlink" href="#rank-slicing" title="Link to this heading">#</a></h3>
<p>Hopefully you‚Äôre familiar with slicing in numpy/Python. Review at the <a class="reference external" href="https://docs.python.org/3/tutorial/introduction.html#lists">Python Tutorial</a> and the <a class="reference external" href="https://numpy.org/doc/stable/reference/arrays.indexing.html">numpy tutorial</a> for a refresher if you need it. <strong>Rank Slicing</strong> is just my terminology for slicing without knowing the rank of a tensor. Use the <code class="docutils literal notranslate"><span class="pre">...</span></code> (ellipsis) keyword. This allows you to account for unknown rank when slicing. Examples:</p>
<ul class="simple">
<li><p>Access last axis: <code class="docutils literal notranslate"><span class="pre">a[...,:]</span></code></p></li>
<li><p>Access last 2 axes: <code class="docutils literal notranslate"><span class="pre">a[...,:,:]</span></code></p></li>
<li><p>Add new axis to end <code class="docutils literal notranslate"><span class="pre">a[...,np.newaxis]</span></code></p></li>
<li><p>Add new axis to beginning <code class="docutils literal notranslate"><span class="pre">a[np.newaxis,...]</span></code></p></li>
</ul>
<hr class="docutils" />
<p>Let‚Äôs see if we can put together our skills to implement the equation example from above,</p>
<div class="amsmath math notranslate nohighlight" id="equation-a0e03b3a-c39d-48af-aa8c-eb86ef018135">
<span class="eqno">(1.14)<a class="headerlink" href="#equation-a0e03b3a-c39d-48af-aa8c-eb86ef018135" title="Permalink to this equation">#</a></span>\[\begin{equation}
    g = \exp\left(a - b\right)^2
\end{equation}\]</div>
<p>for arbitrary rank <span class="math notranslate nohighlight">\(a\)</span>. Recall <span class="math notranslate nohighlight">\(b\)</span> is a rank 1 tensor and we want <span class="math notranslate nohighlight">\(g\)</span> to be the rank of <span class="math notranslate nohighlight">\(a + 1\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">eq</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">((</span><span class="n">a</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span> <span class="o">-</span> <span class="n">b</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>


<span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
<span class="n">a1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="n">a2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

<span class="n">g1</span> <span class="o">=</span> <span class="n">eq</span><span class="p">(</span><span class="n">a1</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;input a1:&quot;</span><span class="p">,</span> <span class="n">a1</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="s2">&quot;output:&quot;</span><span class="p">,</span> <span class="n">g1</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="n">g2</span> <span class="o">=</span> <span class="n">eq</span><span class="p">(</span><span class="n">a2</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;input a2:&quot;</span><span class="p">,</span> <span class="n">a2</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="s2">&quot;output:&quot;</span><span class="p">,</span> <span class="n">g2</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>input a1: (4, 3) output: (4, 3, 4)
input a2: (4, 3, 2, 1) output: (4, 3, 2, 1, 4)
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="view-vs-copy">
<h2><span class="section-number">1.5. </span>View vs Copy<a class="headerlink" href="#view-vs-copy" title="Link to this heading">#</a></h2>
<aside class="margin sidebar">
<p class="sidebar-title"></p>
<p>In most machine learning frameworks, it is actually not possible to modify an array because element assignment interferes with automatic differentiation. So this distinction of a view vs a copy is irrelevant.</p>
</aside>
<p>Most slicing and reshaping operations produce a <strong>view</strong> of the original array. That means no copy operation is done. This is default behavior in all frameworks to reduce required memory ‚Äì you can slice as much as you want without increasing memory use. This typically has no consequences for how we program; it is more of an optimization detail. However, if you modify elements in a view, you will also modify the original array from which the view was constructed. Sometimes this can be unexpected. You should not rely on this behavior though, because in <code class="docutils literal notranslate"><span class="pre">numpy</span></code> a copy may be returned for certain <a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.reshape.html#numpy.reshape" title="(in NumPy v2.4)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">np.reshape</span></code></a> and <a class="reference external" href="https://numpy.org/doc/stable/reference/arrays.indexing.html#advanced-indexing">slicing commands</a>. Thus, I recommend being aware that views may be returned as an optimization, but not assume that is always the case. If you actually want a copy you should explicitly create a copy, like with <a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.copy.html#numpy.copy" title="(in NumPy v2.4)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">np.copy</span></code></a>.</p>
</section>
<section id="chapter-summary">
<h2><span class="section-number">1.6. </span>Chapter Summary<a class="headerlink" href="#chapter-summary" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>Tensors are the building blocks of machine learning. A tensor has a rank and shape that specifies how many elements it has and how they are arranged. An axis describes each element in the shape.</p></li>
<li><p>A euclidean vector is a rank 1 tensor with shape (3). It has 1 axis of dimension 3. A matrix is a rank 2 tensor. It has two axes.</p></li>
<li><p>Equations that describe operating on 1 or more tensors can be written using Einstein notation. Einstein notation uses indices to indicate the shape of tensors, how things are summed, and which axes must match up.</p></li>
<li><p>There are operations that reduce ranks of tensors, like <code class="docutils literal notranslate"><span class="pre">sum</span></code> or <code class="docutils literal notranslate"><span class="pre">mean</span></code>.</p></li>
<li><p>Broadcasting is an automatic tool in programming languages that modifies shapes of tensors with different shapes to be compatible with operations like addition or division.</p></li>
<li><p>Tensors can be reshaped or have rank modified by <code class="docutils literal notranslate"><span class="pre">newaxis</span></code>, <code class="docutils literal notranslate"><span class="pre">reshape</span></code>, and <code class="docutils literal notranslate"><span class="pre">squeeze</span></code>. These are not standardized among the various numeric libraries in Python.</p></li>
</ul>
</section>
<section id="exercises">
<h2><span class="section-number">1.7. </span>Exercises<a class="headerlink" href="#exercises" title="Link to this heading">#</a></h2>
<section id="id2">
<h3><span class="section-number">1.7.1. </span>Einstein notation<a class="headerlink" href="#id2" title="Link to this heading">#</a></h3>
<p>Write out the following in Einstein notation:</p>
<ol class="arabic simple">
<li><p>Matrix product of two matrices</p></li>
<li><p>Trace of a matrix</p></li>
<li><p><a class="reference external" href="https://en.wikipedia.org/wiki/Outer_product">Outer product</a> of two Euclidean vectors</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{A}\)</span> is a rank 3 tensor whose last axis is dimension 3 and contains Euclidean vectors. <span class="math notranslate nohighlight">\(\mathbf{B}\)</span> is Euclidean vector. Compute the dot product of each of the vectors in <span class="math notranslate nohighlight">\(\mathbf{A}\)</span> with B. So if <span class="math notranslate nohighlight">\(\mathbf{A}\)</span> is shape (11, 7, 3), it contains 11 <span class="math notranslate nohighlight">\(\times\)</span> 7 vectors and the output should be shape (11,7). <span class="math notranslate nohighlight">\(\mathbf{B}\)</span> is shape (3)</p></li>
</ol>
</section>
<section id="reductions">
<h3><span class="section-number">1.7.2. </span>Reductions<a class="headerlink" href="#reductions" title="Link to this heading">#</a></h3>
<p>Answer the following with Python code with reductions. Write your code to be as general as possible ‚Äì being able to take arbitrary rank tensors unless it is specified that something is a vector.</p>
<ol class="arabic simple">
<li><p>Normalize a vector so that the sum of its elements is 1. Note the rank of the vector should be unchanged.</p></li>
<li><p>Normalize the last axis of a tensor</p></li>
<li><p>Compute the mean squared error between two tensors</p></li>
<li><p>Compute the mean squared error between the last axis of tensor <span class="math notranslate nohighlight">\(\mathbf{A}\)</span> and vector <span class="math notranslate nohighlight">\(\vec{b}\)</span></p></li>
</ol>
</section>
<section id="broadcasting-and-shapes">
<h3><span class="section-number">1.7.3. </span>Broadcasting and Shapes<a class="headerlink" href="#broadcasting-and-shapes" title="Link to this heading">#</a></h3>
<ol class="arabic simple">
<li><p>Consider two vectors <span class="math notranslate nohighlight">\(\vec{a}\)</span> and <span class="math notranslate nohighlight">\(\vec{b}\)</span>. Using reshaping and broadcasting alone, write python code to compute their outer product.</p></li>
<li><p>Why is the code <code class="docutils literal notranslate"><span class="pre">a.reshape((-1,</span> <span class="pre">3,</span> <span class="pre">-1))</span></code> invalid?</p></li>
<li><p>You have a tensor of unknown rank <span class="math notranslate nohighlight">\(\mathbf{A}\)</span> and would like to subtract both 3.5 and 2.5 from every element, giving two outputs for every input. Your output will be a new tensor <span class="math notranslate nohighlight">\(\mathbf{B}\)</span> with rank <span class="math notranslate nohighlight">\(\textrm{rank}(\mathbf{A}) + 1\)</span>. The last axis of <span class="math notranslate nohighlight">\(\mathbf{B}\)</span> should be dimension 2. Here is the example:</p></li>
</ol>
<div class="highlight-py notranslate"><div class="highlight"><pre><span></span><span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">10</span><span class="p">])</span>
<span class="n">f</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<span class="c1"># prints [[6.5, 7.5]]</span>

<span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">6</span><span class="p">]])</span>
<span class="n">f</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>
<span class="c1"># [[[ 1.5  2.5]</span>
<span class="c1">#  [-0.5  0.5]</span>
<span class="c1">#  [-3.5 -2.5]]</span>

<span class="c1"># [[-3.5 -2.5]</span>
<span class="c1">#  [-1.5 -0.5]</span>
<span class="c1">#  [ 2.5  3.5]]]</span>
</pre></div>
</div>
</section>
</section>
<section id="cited-references">
<h2><span class="section-number">1.8. </span>Cited References<a class="headerlink" href="#cited-references" title="Link to this heading">#</a></h2>
<div class="docutils container" id="id3">
<div role="list" class="citation-list">
<div class="citation" id="id191" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id1">Str20</a><span class="fn-bracket">]</span></span>
<p>J¬†Straub. Mathematical methods for molecular science. 2020.</p>
</div>
</div>
</div>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./math"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="../index.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Overview</p>
      </div>
    </a>
    <a class="right-next"
       href="../ml/introduction.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">2. </span>Introduction to Machine Learning</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#einstein-notation">1.1. Einstein Notation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#tensor-operations">1.2. Tensor Operations</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#reduction-operations">1.2.1. Reduction Operations</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#element-operations">1.2.2. Element Operations</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#broadcasting">1.3. Broadcasting</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#suggested-reading-for-broadcasting">1.3.1. Suggested Reading for Broadcasting</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#modifying-rank">1.4. Modifying Rank</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#reshaping">1.4.1. Reshaping</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#rank-slicing">1.4.2. Rank Slicing</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#view-vs-copy">1.5. View vs Copy</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#chapter-summary">1.6. Chapter Summary</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#exercises">1.7. Exercises</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">1.7.1. Einstein notation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#reductions">1.7.2. Reductions</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#broadcasting-and-shapes">1.7.3. Broadcasting and Shapes</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cited-references">1.8. Cited References</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Andrew D. White
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      ¬© Copyright 2026.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
<div class="extra_footer">
  <a href="http://thewhitelab.org">thewhitelab.org</a> <div id="wh-modal"> <button class="wh-venti-button" aria-label="close modal" id="wh-modal-close">‚úï</button> <img id="wh-modal-img"> </div>
</div>
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>